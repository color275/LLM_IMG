# export AWS_DEFAULT_REGION='us-west-2'
# nohup streamlit run app.py --server.port 8503 &

import streamlit as st
import fitz
import logging
import boto3
import json
import os
import re
import pymysql
import pandas as pd
from PIL import Image
import base64
import io
from dotenv import load_dotenv
from datetime import datetime
from langchain_community.chat_models import BedrockChat
from langchain_community.embeddings import BedrockEmbeddings
from langchain_community.vectorstores import OpenSearchVectorSearch
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.llms.bedrock import Bedrock
from opensearchpy import OpenSearch, RequestsHttpConnection
from opensearchpy.helpers import bulk
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-west-2')

################################################################################

load_dotenv()
opensearch_username = os.getenv('OPENSEARCH_USERNAME')
opensearch_password = os.getenv('OPENSEARCH_PASSWORD')
opensearch_endpoint = os.getenv('OPENSEARCH_ENDPOINT')
index_name = os.getenv('OPENSEARCH_INDEX_NAME')
mysql_host = os.getenv('MYSQL_HOST')
mysql_port = os.getenv('MYSQL_PORT')
mysql_user = os.getenv('MYSQL_USER')
mysql_password = os.getenv('MYSQL_PASSWORD')
mysql_db = os.getenv('MYSQL_DB')

bedrock_region = 'us-west-2'
stop_record_count = 100
record_stop_yn = False
bedrock_model_id = "anthropic.claude-3-sonnet-20240229-v1:0"
bedrock_embedding_model_id = "amazon.titan-embed-text-v1"
################################################################################


def get_opensearch_cluster_client():
    opensearch_client = OpenSearch(
        hosts=[{
            'host': opensearch_endpoint,
            'port': 443
        }],
        http_auth=(opensearch_username, opensearch_password),
        index_name=index_name,
        use_ssl=True,
        verify_certs=True,
        connection_class=RequestsHttpConnection,
        timeout=30
    )
    return opensearch_client


def get_bedrock_client():
    bedrock_client = boto3.client(
        "bedrock-runtime", region_name=bedrock_region)
    return bedrock_client


def create_langchain_vector_embedding_using_bedrock(bedrock_client):
    bedrock_embeddings_client = BedrockEmbeddings(
        client=bedrock_client,
        model_id=bedrock_embedding_model_id)
    return bedrock_embeddings_client


def create_opensearch_vector_search_client(bedrock_embeddings_client, _is_aoss=False):
    docsearch = OpenSearchVectorSearch(
        index_name=index_name,
        embedding_function=bedrock_embeddings_client,
        opensearch_url=f"https://{opensearch_endpoint}",
        http_auth=(opensearch_username, opensearch_password),
        is_aoss=_is_aoss
    )
    return docsearch


def create_bedrock_llm():
    # claude-2 Ïù¥Ìïò
    # bedrock_llm = Bedrock(
    #     model_id=model_version_id,
    #     client=bedrock_client,
    #     model_kwargs={'temperature': 0}
    #     )
    # bedrock_llm = BedrockChat(model_id=model_version_id, model_kwargs={'temperature': 0}, streaming=True)

    bedrock_llm = BedrockChat(
        model_id=bedrock_model_id, 
        model_kwargs={'temperature': 1,
                      "top_k": 250,
                      "top_p": 0.999,
                      "max_tokens": 4096
                      },
        streaming=True,
        callbacks=[StreamingStdOutCallbackHandler()]
        )
    return bedrock_llm


def get_bedrock_client():
    bedrock_client = boto3.client(
        "bedrock-runtime", region_name=bedrock_region)
    return bedrock_client


def create_vector_embedding_with_bedrock(text, bedrock_client):
    payload = {"inputText": f"{text}"}
    body = json.dumps(payload)
    modelId = "amazon.titan-embed-text-v1"
    accept = "application/json"
    contentType = "application/json"

    response = bedrock_client.invoke_model(
        body=body, modelId=modelId, accept=accept, contentType=contentType
    )
    response_body = json.loads(response.get("body").read())

    embedding = response_body.get("embedding")
    return {"_index": index_name, "text": text, "vector_field": embedding}


def extract_sentences_from_pdf(opensearch_client, pdf_file, progress_bar, progress_text):
    try:
        logging.info(
            f"Checking if index {index_name} exists in OpenSearch cluster")

        exists = opensearch_client.indices.exists(index=index_name)

        if not exists:
            body = {
                'settings': {
                    'index': {
                        'number_of_shards': 3,
                        'number_of_replicas': 2,
                        "knn": True,
                        "knn.space_type": "cosinesimil"
                    }
                }
            }
            success = opensearch_client.indices.create(index_name, body=body)
            if success:
                body = {
                    "properties": {
                        "vector_field": {
                            "type": "knn_vector",
                            "dimension": 1536
                        },
                        "text": {
                            "type": "keyword"
                        }
                    }
                }
                success = opensearch_client.indices.put_mapping(
                    index=index_name,
                    body=body
                )

        doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
        all_records = []
        for page in doc:
            all_records.append(page.get_text())

        # URL Scraping
        # doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
        # all_text = ""
        # for page in doc:
        #     all_text += page.get_text()
        # doc.close()
        # all_records = re.split(r'(?<=[.!?])\s+', all_text)

        logging.info(f"PDF LIST Í∞úÏàò : {len(all_records)}")

        total_records = len(all_records)
        processed_records = 0

        bedrock_client = get_bedrock_client()

        all_json_records = []

        for record in all_records:
            if record_stop_yn and processed_records > stop_record_count:

                success, failed = bulk(opensearch_client, all_json_records)
                break

            records_with_embedding = create_vector_embedding_with_bedrock(
                record, bedrock_client)
            all_json_records.append(records_with_embedding)

            processed_records += 1
            progress = int((processed_records / total_records) * 100)
            progress_bar.progress(progress)

            if processed_records % 500 == 0 or processed_records == len(all_records):

                success, failed = bulk(opensearch_client, all_json_records)
                all_json_records = []

        progress_text.text("ÏôÑÎ£å")
        logging.info("ÏûÑÎ≤†Îî©ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Î†àÏΩîÎìú ÏÉùÏÑ± ÏôÑÎ£å")

        return total_records
    except Exception as e:
        print(str(e))
        st.error('PDFÎ•º ÏûÑÎ≤†Îî© ÌïòÎäî Í≥ºÏ†ïÏóêÏÑú Ïò§Î•òÍ∞Ä Î∞úÏÉùÎêòÏóàÏäµÎãàÎã§.')
        return 0


def find_answer_in_sentences(image_description, user_keyword):
    try:
        # question = question + " Ï†ïÎ≥¥Í∞Ä ÏóÜÎã§Îäî Ïù¥ÏïºÍ∏∞Îäî ÌïòÏßÄ ÎßêÍ≥†, Ï†úÍ≥µÎêú Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú ÎÑàÍ∞Ä SQLÏùÑ ÎßåÎì§Ïñ¥Ï§ò."
        # Ïù¥ÎØ∏ÏßÄ Ï†ïÎ≥¥, ÏÇ¨Ïö©Ïûê ÌÇ§ÏõåÎìú Í∑∏Î¶¨Í≥† Ï†úÍ≥µÎêú Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Î¶¨Î∑∞Î•º Î≥¥ÏôÑÌï¥ÏÑú ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
        question = f"""
        Ïù¥ Ïù¥ÎØ∏ÏßÄÎäî "{image_description}"ÏôÄ Í¥ÄÎ†®Ïù¥ ÏûàÏäµÎãàÎã§. 
        ÏÇ¨Ïö©ÏûêÍ∞Ä Ï†úÏãúÌïú ÏÇ¨Ïö©Ïûê ÌÇ§ÏõåÎìúÎäî "{user_keyword}" ÏûÖÎãàÎã§.
        Ïó¨ÌñâÏ†úÎ™©Ïùò Í∏ÄÏûêÏÉâÏùÄ Ìù∞ÏÉâÏúºÎ°ú ÌëúÏãúÌï¥Ï§ò.
        Î¶¨Î∑∞ÎÇ¥Ïö©Ïóê ÏÇ¨Ïö©Ïûê ÌÇ§ÏõåÎìúÏôÄ ÎπÑÏä∑Ìïú Î¨∏Íµ¨Îäî markdownÏùò ÌÉúÍ∑∏Î•º ÌôúÏö©Ìï¥ÏÑú ÎÖπÏÉâÏúºÎ°ú ÌëúÏãúÌï¥Ï§ò.
        ÎßåÏïΩ Ï†úÍ≥µÎêú Ï†ïÎ≥¥ Ï§ë ÏÇ¨Ïö©Ïûê ÌÇ§ÏõåÎìúÏôÄ Í¥ÄÍ≥ÑÎêú ÎÇ¥Ïö©Ïù¥ ÏóÜÎã§Î©¥ Ï†úÍ≥µÎêú Ï†ïÎ≥¥Î•º ÏÇ¨Ïö©ÌïòÏßÄ ÎßêÍ≥† ÌÇ§ÏõåÎìú Ï§ëÏã¨ÏúºÎ°ú Ï†ÅÏ†àÌïòÍ≤å Î¶¨Î∑∞Î•º 400Ïûê ÎÇ¥Î°ú ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî."""

        print("## question : ",question)

        bedrock_client = get_bedrock_client()
        bedrock_llm = create_bedrock_llm()

        bedrock_embeddings_client = create_langchain_vector_embedding_using_bedrock(
            bedrock_client)

        opensearch_vector_search_client = create_opensearch_vector_search_client(
            bedrock_embeddings_client)
        
        
        # Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. don't include harmful content        
        # SQL ÏÉùÏÑ± Ïãú ÏµúÎåÄ 10Í∞úÏùò Î†àÏΩîÎìúÎßå ÌëúÏãúÎêòÎèÑÎ°ù SQLÏùò Í∞ÄÏû• ÌïòÎã®Ïóê Limit 10ÏùÑ SQLÏóê Ìè¨Ìï®ÏãúÏºúÏ§ò. Í∑∏Î¶¨Í≥† Limit 10ÏùÑ ÏûÑÏùòÎ°ú Ï∂îÍ∞ÄÌñàÎã§Í≥† Ï¥àÎ°ùÏÉâ Í∏ÄÏûêÎ°ú ÏïàÎÇ¥Ìï¥Ï§ò.
        prompt_template = """
        Use the following pieces of context to answer the question at the end.       

        {context}
        Ï†úÍ≥µÎêú Ï†ïÎ≥¥ Ï§ë ÏÇ¨Ïö©Ïûê ÌÇ§ÏõåÎìúÏôÄ Í¥ÄÎ†®ÏûàÎäî Ï†ïÎ≥¥Îßå ÏÇ¨Ïö©Ìï¥Ï§ò.
        Îã§Î•∏ ÏïàÎÇ¥ Î¨∏Ïû•ÏùÄ Ï†úÍ≥µÌïòÏßÄ ÎßêÍ≥† Ïó¨Ìñâ Î¶¨Î∑∞Îßå ÏûëÏÑ±Ìï¥Ï§ò.
        Ïó¨Ìñâ Ï†úÎ™©Ïùò Í∏ÄÏûê ÌÅ¨Í∏∞Îäî markdownÏùò H3 ÏÇ¨Ïù¥Ï¶àÎ•º ÏÇ¨Ïö©Ìï¥Ï§ò.

        Question: {question}
        Answer:
        ## Ïó¨ÌñâÏ†úÎ™©
        Ïó¨Í∏∞Ïóê Î¶¨Î∑∞ÎÇ¥Ïö©ÏùÑ Ïç®Ï£ºÏÑ∏Ïöî. ÎÇ¥Ïö©ÏùÄ Í∞ÑÍ≤∞ÌïòÎ©¥ÏÑúÎèÑ Ïó¨ÌñâÏùò ÌïµÏã¨ Í≤ΩÌóòÏùÑ Îã¥ÏïÑÏïº Ìï©ÎãàÎã§."""
        
        prompt_template = PromptTemplate(
            template=prompt_template, input_variables=["context", "question"]
        )

        # prompt = prompt_template.format(
        #     context=CONTEXT_DATA, question=question)
        
        # print("# prompt : ", prompt)


        logging.info(
            f"Starting the chain with KNN similarity using OpenSearch, Bedrock FM {bedrock_model_id}, and Bedrock embeddings with {bedrock_embedding_model_id}")

        qa = RetrievalQA.from_chain_type(llm=bedrock_llm,
                                         chain_type="stuff",
                                         retriever=opensearch_vector_search_client.as_retriever(),
                                         return_source_documents=True,
                                         chain_type_kwargs={
                                             "prompt": prompt_template, "verbose": True},
                                         verbose=True)

        # response = qa({"context": CONTEXT_DATA, "query": question},
        #               return_only_outputs=False)
        response = qa(question,
                      return_only_outputs=False)

        source_documents = response.get('source_documents')
        # logging.info(f"The answer from Bedrock {bedrock_model_id} is: {response.get('result')}")
        return f"{response.get('result')}"
    except Exception as e:
        if 'index_not_found_exception' in str(e):
            st.error('Ïù∏Îç±Ïä§Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. PDF ÌååÏùºÏùÑ ÏóÖÎ°úÎìú ÌñàÎäîÏßÄ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî')
        else:
            print(str(e))
            st.error('ÎãµÎ≥ÄÏùÑ Ï∞æÎäî Í≥ºÏ†ïÏóêÏÑú ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.')
        return "Ïò§Î•òÎ°ú Ïù∏Ìï¥ ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌï† Ïàò ÏóÜÏäµÎãàÎã§."

def connect_to_database():
    return pymysql.connect(
        host=mysql_host,
        port=int(mysql_port),
        user=mysql_user,
        password=mysql_password,
        database=mysql_db,
        charset='utf8mb4'
    )

# SQL ÏøºÎ¶¨ Ïã§Ìñâ Î∞è Í≤∞Í≥ºÎ•º Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏúºÎ°ú Î≥ÄÌôò


def execute_query_and_return_df(sql):
    conn = connect_to_database()
    try:
        with conn.cursor() as cursor:
            cursor.execute(sql)
            result = cursor.fetchall()
            df = pd.DataFrame(result, columns=[i[0]
                              for i in cursor.description])
    finally:
        conn.close()
    return df

def scan_using_bedrock(image, user_keyword) :
    base64_encoded_image = get_image_base64(image)
    
    # Î¶¨Î∑∞Îäî 200Í∏ÄÏûê Ïù¥ÎÇ¥Î°ú ÏöîÏïΩÌïòÎ©∞, Markdown Ïñ∏Ïñ¥Î•º ÏÇ¨Ïö©ÌïòÏó¨ Ìè¨Îß∑Ìï¥Ï£ºÏÑ∏Ïöî. 
    # Ï§ëÏöîÌïú Î∂ÄÎ∂ÑÏùÄ bold ÌÉúÍ∑∏Î°ú Í∞ïÏ°∞ÌïòÏÑ∏Ïöî.
    # ## Ïó¨Ìñâ Ï†úÎ™©
    # Ïó¨Í∏∞Ïóê Î¶¨Î∑∞ ÎÇ¥Ïö©ÏùÑ Ïç®Ï£ºÏÑ∏Ïöî. ÎÇ¥Ïö©ÏùÄ Í∞ÑÍ≤∞ÌïòÎ©¥ÏÑúÎèÑ Ïó¨ÌñâÏùò ÌïµÏã¨ Í≤ΩÌóòÏùÑ Îã¥ÏïÑÏïº Ìï©ÎãàÎã§."
    prompt = f"""
    "Ïó¨Ìñâ Ï§ë Ï∞çÏùÄ ÏÇ¨ÏßÑÏùÑ Í∏∞Î∞òÏúºÎ°ú, 1Ïù∏Ïπ≠ ÏãúÏ†êÏóêÏÑú Ïó¨Ìñâ Í≤ΩÌóò Î¶¨Î∑∞Î•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî. 
    Ïù¥ ÏÇ¨ÏßÑÏùò ÌÇ§ÏõåÎìúÎäî "{user_keyword}" Ïù¥Î©∞ ÌÇ§ÏõåÎìúÎ•º Ï§ëÏã¨ÏúºÎ°ú Î¶¨Î∑∞Î•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
    Î¶¨Î∑∞Îäî 200Í∏ÄÏûê Ïù¥ÎÇ¥Î°ú ÏöîÏïΩÌï¥Ï£ºÏÑ∏Ïöî.
    ÌïúÍ∏ÄÎ°ú ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
    """

    payload = {
        "modelId": "anthropic.claude-3-sonnet-20240229-v1:0",
        "contentType": "application/json",
        "accept": "application/json",
        "body": {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 40960,
            "top_k": 250,
            "top_p": 0.999,
            "temperature": 1,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",
                                "data": base64_encoded_image
                            }
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ]
        }
    }

    # Convert the payload to bytes
    body_bytes = json.dumps(payload['body']).encode('utf-8')

    # Invoke the model
    response = bedrock_runtime.invoke_model(
        body=body_bytes,
        contentType=payload['contentType'],
        accept=payload['accept'],
        modelId=payload['modelId']
    )

    # Process the response
    response_body = json.loads(response['body'].read())
    result = response_body['content'][0]['text']
    return result

# def resize_image(image, max_size=1048576, quality=90):
def resize_image(image, target_size_mb=1, quality=85):
    """
    Ïù¥ÎØ∏ÏßÄÎ•º Ï£ºÏñ¥ÏßÑ ÌÉÄÍ≤ü ÏÇ¨Ïù¥Ï¶à(Î©îÍ∞ÄÎ∞îÏù¥Ìä∏) ÎØ∏ÎßåÏúºÎ°ú Î¶¨ÏÇ¨Ïù¥Ï¶àÌï©ÎãàÎã§.
    JPEG Ìè¨Îß∑ÏúºÎ°ú ÏïïÏ∂ïÌïòÏó¨ ÏÇ¨Ïù¥Ï¶àÎ•º Ï§ÑÏûÖÎãàÎã§.
    """
    # ÌÉÄÍ≤ü ÏÇ¨Ïù¥Ï¶àÎ•º Î∞îÏù¥Ìä∏Î°ú Î≥ÄÌôò (1MB = 1 * 1024 * 1024 Î∞îÏù¥Ìä∏)
    target_size_bytes = target_size_mb * 1024 * 1024
    
    img_buffer = io.BytesIO()
    image.save(img_buffer, format='JPEG', quality=quality)
    img_size = img_buffer.tell()

    # Ïù¥ÎØ∏ÏßÄ ÏÇ¨Ïù¥Ï¶àÍ∞Ä ÌÉÄÍ≤üÎ≥¥Îã§ ÌÅ∞ Í≤ΩÏö∞ Î¶¨ÏÇ¨Ïù¥Ï¶à
    while img_size > target_size_bytes:
        img_buffer = io.BytesIO()
        width, height = image.size
        # Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î•º 10%Ïî© Ï§ÑÏûÑ
        image = image.resize((int(width * 0.9), int(height * 0.9)), Image.Resampling.LANCZOS)
        # Îã§Ïãú Ï†ÄÏû•ÌïòÏó¨ ÏÇ¨Ïù¥Ï¶à Ï≤¥ÌÅ¨
        image.save(img_buffer, format='JPEG', quality=quality)
        img_size = img_buffer.tell()

    # Î≤ÑÌçºÏùò Ìè¨ÏßÄÏÖòÏùÑ 0ÏúºÎ°ú Î¶¨ÏÖã
    img_buffer.seek(0)
    # BytesIO Í∞ùÏ≤¥Î•º PIL Ïù¥ÎØ∏ÏßÄÎ°ú Îã§Ïãú Î≥ÄÌôò
    return Image.open(img_buffer)

def get_image_base64(image, quality=85):
    """
    Ïù¥ÎØ∏ÏßÄ ÌååÏùºÏùÑ Î∞õÏïÑÏÑú JPEG Ìè¨Îß∑ÏúºÎ°ú ÏïïÏ∂ïÌïòÍ≥†,
    Base64 Ïù∏ÏΩîÎî©Îêú Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôòÌï©ÎãàÎã§.
    `quality` ÌååÎùºÎØ∏ÌÑ∞Î°ú Ïù¥ÎØ∏ÏßÄÏùò ÏïïÏ∂ï ÌíàÏßàÏùÑ Ï°∞Ï†àÌï† Ïàò ÏûàÏäµÎãàÎã§.
    """
    buffered = io.BytesIO()
    # JPEG Ìè¨Îß∑ÏúºÎ°ú Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû• Î∞è ÌíàÏßà Ï°∞Ï†à
    image.save(buffered, format="JPEG", quality=quality)
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return img_str

def main():

    # Í∏∞Ï°¥ ÏóÖÎ°úÎìú Î¨∏ÏÑú ÏÇ≠Ï†ú
    # if st.sidebar.button("Í∏∞Ï°¥ ÏóÖÎ°úÎìú Î¨∏ÏÑú ÏÇ≠Ï†ú"):
    #     response = opensearch_client.delete_opensearch_index(opensearch_client, index_name)
    #     # st.session_state['question'] = ""  # ÏßàÎ¨∏ ÏÑ∏ÏÖò ÏÉÅÌÉú Ï¥àÍ∏∞Ìôî
    #     if response:
    #         logging.info("OpenSearch index successfully deleted")
    #         st.sidebar.success("OpenSearch Ïù∏Îç±Ïä§Í∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§.")  # ÏÑ±Í≥µ ÏïåÎ¶º Ï∂îÍ∞Ä

    opensearch_client = get_opensearch_cluster_client()
    
    # Í∏∞Ï°¥ ÏóÖÎ°úÎìú Î¨∏ÏÑú ÏÇ≠Ï†ú
    # opensearch_client.indices.delete(index=index_name)
    
    st.set_page_config(page_title='ü§ñ Chat with Bedrock', layout='wide')
    # st.header('_Chatbot_ using :blue[OpenSearch] :sunglasses:', divider='rainbow')
    st.header(':blue[Î¶¨Î∑∞Í∞Ä] _Í∂ÅÍ∏àÌï¥_ :sunglasses:', divider='rainbow')    

    if 'qa_history' not in st.session_state:
        st.session_state.qa_history = []

    with st.sidebar:
        st.sidebar.markdown(
            ':smile: **Createby:** chiholee@amazon.com', unsafe_allow_html=True)
        
        st.sidebar.markdown('---')
        user_keyword = st.text_input('(ÌïÑÏàò)Ïó¨Ìñâ ÌÇ§ÏõåÎìúÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî')
        
        if user_keyword is not None :
            st.session_state['user_keyword'] = user_keyword

        st.title("IMG Upload")        
        img_file = st.file_uploader(
            "Ïù¥ÎØ∏ÏßÄÎ•º ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî.", type=['jpg', 'png', 'jpeg'])
        
        if img_file is not None :
            st.session_state['img_file'] = img_file

        st.sidebar.markdown('---')
        st.title("RAG Embedding")
        pdf_file = st.file_uploader(
            "PDF ÏóÖÎ°úÎìúÎ•º ÌÜµÌï¥ Ï∂îÍ∞Ä ÌïôÏäµÏùÑ Ìï† Ïàò ÏûàÏäµÎãàÎã§.", type=["pdf"], key=None)
        

        if 'last_uploaded' not in st.session_state:
            st.session_state.last_uploaded = None

        if pdf_file is not None and pdf_file != st.session_state.last_uploaded:
            progress_text = st.empty()
            st.session_state['progress_bar'] = st.progress(0)
            progress_text.text("RAG(OpenSearch) ÏûÑÎ≤†Îî© Ï§ë...")
            record_cnt = extract_sentences_from_pdf(
                opensearch_client, pdf_file, st.session_state['progress_bar'], progress_text)
            if record_cnt > 0:
                st.session_state['processed'] = True
                st.session_state['record_cnt'] = record_cnt
                st.session_state['progress_bar'].progress(100)
                st.session_state.last_uploaded = pdf_file
                st.success(f"{record_cnt} Vector ÏûÑÎ≤†Îî© ÏôÑÎ£å!")

    
    
    if 'img_file' in st.session_state and not user_keyword :
        st.error('ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌïòÍ∏∞ Ï†ÑÏóê ÌÇ§ÏõåÎìúÎ•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.')            

    elif 'img_file' in st.session_state :
        
        col1, col2 = st.columns(2)

        image = Image.open(st.session_state['img_file'])        
        # image = resize_image(image)

        image_description = scan_using_bedrock(image, st.session_state['user_keyword'])
        review = find_answer_in_sentences(image_description, st.session_state['user_keyword'])

        with col1:
            st.subheader("üì∑ Image")
            st.image(image, caption='Uploaded Image.', use_column_width=True)

        with col2:
            st.subheader("üîç Review")
            st.markdown(review, unsafe_allow_html=True)

        
        st.sidebar.markdown('---')
        ref1, ref2, ref3 = st.columns([1,3,3])
        with ref1 :
            st.write("üìù ÏûÖÎ†• Keyword")
            st.markdown(st.session_state['user_keyword'], unsafe_allow_html=True)
        with ref2 :
            st.write("üìù Keyword + Image Í∏∞Î∞ò LLM")
            st.markdown(image_description, unsafe_allow_html=True)
        with ref3 :
            st.write("üìù Keyword + Image + RAG Í∏∞Î∞ò LLM")
            st.markdown(review, unsafe_allow_html=True)
    
    

if __name__ == "__main__":
    main()
