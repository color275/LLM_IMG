# export AWS_DEFAULT_REGION='us-west-2'
# nohup streamlit run app.py --server.port 8502 &

import streamlit as st
import fitz
import logging
import boto3
import json
import os
import re
import pymysql
import pandas as pd
from PIL import Image
import base64
import io
from dotenv import load_dotenv
from datetime import datetime
from langchain_community.chat_models import BedrockChat
from langchain_community.embeddings import BedrockEmbeddings
from langchain_community.vectorstores import OpenSearchVectorSearch
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.llms.bedrock import Bedrock
from opensearchpy import OpenSearch, RequestsHttpConnection
from opensearchpy.helpers import bulk
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-west-2')

INIT_MESSAGE = {"role": "assistant",
                "type": "text",
                "content": """
ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” <font color='red'><b>Amazon Bedrockê³¼ Claude3</b></font>ë¥¼ í™œìš©í•´ì„œ ì—¬ëŸ¬ë¶„ë“¤ì´ ì°¾ê³  ì‹¶ì€ ë°ì´í„°ë¥¼ ëŒ€ì‹  ì°¾ì•„ì¤„ <i><b>[ë°ì´í„°ê°€ ê¶ê¸ˆí•´]<i><b> ì…ë‹ˆë‹¤. 
<br>ì•„ë˜ì™€ ê°™ì´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.
- <font color='#32CD32;'><b>ì–´ì œ íŒë§¤ëœ ìƒí’ˆ ê¸°ì¤€ìœ¼ë¡œ ì£¼ë¬¸ ê¸ˆì•¡ TOP 5 ë¥¼ ì•Œë ¤ì¤˜</b></font><br>
- <font color='#32CD32;'><b>ì§€ë‚œ ì¼ì£¼ì¼ê°„ ì£¼ë¬¸ ì‹¤ì ì„ ì¼ ë³„ë¡œ ì•Œë ¤ì¤˜</b></font><br>
- <font color='#32CD32;'><b>ìµœê·¼ 5ë¶„ ë™ì•ˆ ì´ì£¼ë¬¸ê¸ˆì•¡ê³¼ ì´ì£¼ë¬¸ìˆ˜ëŸ‰ì„ ë¶„ ë‹¨ìœ„ë¡œ ì•Œë ¤ì¤˜</b></font><br>
- <font color='#32CD32;'><b>ì˜¤ëŠ˜ ì´ ì£¼ë¬¸ê¸ˆì•¡ì´ ê°€ì¥ ì ì€ ìƒí’ˆì„ ì•Œë ¤ì¤˜</b></font><br>
---
ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"""}



################################################################################

load_dotenv()
opensearch_username = os.getenv('OPENSEARCH_USERNAME')
opensearch_password = os.getenv('OPENSEARCH_PASSWORD')
opensearch_endpoint = os.getenv('OPENSEARCH_ENDPOINT')
index_name = os.getenv('OPENSEARCH_INDEX_NAME')

bedrock_region = 'us-west-2'
stop_record_count = 100
record_stop_yn = False
bedrock_model_id = "anthropic.claude-3-sonnet-20240229-v1:0"
bedrock_embedding_model_id = "amazon.titan-embed-text-v1"
################################################################################


def get_opensearch_cluster_client():
    opensearch_client = OpenSearch(
        hosts=[{
            'host': opensearch_endpoint,
            'port': 443
        }],
        http_auth=(opensearch_username, opensearch_password),
        index_name=index_name,
        use_ssl=True,
        verify_certs=True,
        connection_class=RequestsHttpConnection,
        timeout=30
    )
    return opensearch_client


def get_bedrock_client():
    bedrock_client = boto3.client(
        "bedrock-runtime", region_name=bedrock_region)
    return bedrock_client


def create_langchain_vector_embedding_using_bedrock(bedrock_client):
    bedrock_embeddings_client = BedrockEmbeddings(
        client=bedrock_client,
        model_id=bedrock_embedding_model_id)
    return bedrock_embeddings_client


def create_opensearch_vector_search_client(bedrock_embeddings_client, _is_aoss=False):
    docsearch = OpenSearchVectorSearch(
        index_name=index_name,
        embedding_function=bedrock_embeddings_client,
        opensearch_url=f"https://{opensearch_endpoint}",
        http_auth=(opensearch_username, opensearch_password),
        is_aoss=_is_aoss
    )
    return docsearch


def create_bedrock_llm():
    bedrock_llm = BedrockChat(
        model_id=bedrock_model_id, 
        model_kwargs={'temperature': 0},
        streaming=True,
        callbacks=[StreamingStdOutCallbackHandler()]
        )
    return bedrock_llm


def get_bedrock_client():
    bedrock_client = boto3.client(
        "bedrock-runtime", region_name=bedrock_region)
    return bedrock_client


def create_vector_embedding_with_bedrock(text, bedrock_client):
    payload = {"inputText": f"{text}"}
    body = json.dumps(payload)
    modelId = "amazon.titan-embed-text-v1"
    accept = "application/json"
    contentType = "application/json"

    response = bedrock_client.invoke_model(
        body=body, modelId=modelId, accept=accept, contentType=contentType
    )
    response_body = json.loads(response.get("body").read())

    embedding = response_body.get("embedding")
    return {"_index": index_name, "text": text, "vector_field": embedding}


def extract_sentences_from_pdf(opensearch_client, pdf_file, progress_bar, progress_text):
    try:
        logging.info(
            f"Checking if index {index_name} exists in OpenSearch cluster")

        exists = opensearch_client.indices.exists(index=index_name)

        if not exists:
            body = {
                'settings': {
                    'index': {
                        'number_of_shards': 3,
                        'number_of_replicas': 2,
                        "knn": True,
                        "knn.space_type": "cosinesimil"
                    }
                }
            }
            success = opensearch_client.indices.create(index_name, body=body)
            if success:
                body = {
                    "properties": {
                        "vector_field": {
                            "type": "knn_vector",
                            "dimension": 1536
                        },
                        "text": {
                            "type": "keyword"
                        }
                    }
                }
                success = opensearch_client.indices.put_mapping(
                    index=index_name,
                    body=body
                )

        doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
        all_records = []
        for page in doc:
            all_records.append(page.get_text())

        logging.info(f"PDF LIST ê°œìˆ˜ : {len(all_records)}")

        total_records = len(all_records)
        processed_records = 0

        bedrock_client = get_bedrock_client()

        all_json_records = []

        for record in all_records:
            if record_stop_yn and processed_records > stop_record_count:

                success, failed = bulk(opensearch_client, all_json_records)
                break

            records_with_embedding = create_vector_embedding_with_bedrock(
                record, bedrock_client)
            all_json_records.append(records_with_embedding)

            processed_records += 1
            progress = int((processed_records / total_records) * 100)
            progress_bar.progress(progress)

            if processed_records % 500 == 0 or processed_records == len(all_records):

                success, failed = bulk(opensearch_client, all_json_records)
                all_json_records = []

        progress_text.text("ì™„ë£Œ")
        logging.info("ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ë ˆì½”ë“œ ìƒì„± ì™„ë£Œ")

        return total_records
    except Exception as e:
        print(str(e))
        st.error('PDFë¥¼ ì„ë² ë”© í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒë˜ì—ˆìŠµë‹ˆë‹¤.')
        return 0

def scan_using_bedrock(image) :
    base64_encoded_image = get_image_base64(image)
    
    # ë‹¤ìŒ [ì§ˆë¬¸], [ë¦¬ë·°ì˜ˆì‹œ]ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ì§„ì— ëŒ€í•œ ì„¤ëª…ê³¼ ëŠë‚€ ì ì„ í¬í•¨í•´ ì£¼ì„¸ìš”.
    # prompt = """
    # ë‹¹ì‹ ì€ ì—¬í–‰ ì¤‘ì— ì°ì€ ì‚¬ì§„ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì‚¬ì§„ì— ë‹´ê¸´ ìˆœê°„ì„ ê¸°ë°˜ìœ¼ë¡œ ì—¬í–‰ ê²½í—˜ì— ëŒ€í•œ ë¦¬ë·°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    # ë¦¬ë·°ëŠ” 1ì¸ì¹­ ì‹œì ì—ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    # markdown ì–¸ì–´ë¡œ ì‘ì„±ì„ í•´ì£¼ê³ , ê°•ì¡°í•  ë¶€ë¶„ì´ ìˆë‹¤ë©´ markdown tagë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
    # 200ê¸€ì ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    # ì•„ë˜ì™€ ê°™ì€ í¬ë§·ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    # ### {íƒ€ì´í‹€}
    # {ë‚´ìš©}
    # """

    prompt = """
    "ì—¬í–‰ ì¤‘ ì°ì€ ì‚¬ì§„ì„ ê¸°ë°˜ìœ¼ë¡œ, 1ì¸ì¹­ ì‹œì ì—ì„œ ì—¬í–‰ ê²½í—˜ ë¦¬ë·°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. 
    ë¦¬ë·°ëŠ” 200ê¸€ì ì´ë‚´ë¡œ ìš”ì•½í•˜ë©°, Markdown ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ í¬ë§·í•´ì£¼ì„¸ìš”. 
    ì¤‘ìš”í•œ ë¶€ë¶„ì€ bold íƒœê·¸ë¡œ ê°•ì¡°í•˜ì„¸ìš”.
    í•œê¸€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ## ì—¬í–‰ ì œëª©
    ì—¬ê¸°ì— ë¦¬ë·° ë‚´ìš©ì„ ì¨ì£¼ì„¸ìš”. ë‚´ìš©ì€ ê°„ê²°í•˜ë©´ì„œë„ ì—¬í–‰ì˜ í•µì‹¬ ê²½í—˜ì„ ë‹´ì•„ì•¼ í•©ë‹ˆë‹¤."
    """

    # prompt = """
    # ìƒì„¸í•˜ê²Œ ë¬˜ì‚¬ëœ ì´ ì´ë¯¸ì§€ëŠ” ì—‘ì…€ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì—¬ëŸ¬ í–‰ê³¼ ì—´ì— ê±¸ì³ ë‹¤ì–‘í•œ ìˆ«ìì™€ ê³„ì‚°ì‹ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    # ê° ì…€ì— ì íŒ ìˆ«ìëŠ” ê²½ì œì  ë¶„ì„, í•™ìˆ  ì—°êµ¬ ë°ì´í„°, ë˜ëŠ” ì¼ìƒì ì¸ ê°€ê³„ë¶€ ê³„ì‚°ê³¼ ê°™ì´ ë‹¤ì–‘í•œ ë§¥ë½ì—ì„œ í•´ì„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ì´ë¯¸ì§€ ë¶„ì„ì„ í†µí•´ ê° ê³„ì‚°ì‹ì˜ ì ìš© ë§¥ë½ê³¼ ê°€ëŠ¥í•œ ì˜ë¯¸ë¥¼ ì„¤ëª…í•˜ê³ , ì´ë¥¼ í†µí•´ ì–»ì„ ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ë‹¤ì–‘í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.
    # markdown ì–¸ì–´ë¡œ ì‘ì„±ì„ í•´ì£¼ê³ , ê°•ì¡°í•  ë¶€ë¶„ì´ ìˆë‹¤ë©´ markdown tagë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
    # í•œê¸€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    # """

    payload = {
        "modelId": "anthropic.claude-3-sonnet-20240229-v1:0",
        "contentType": "application/json",
        "accept": "application/json",
        "body": {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 40960,
            "top_k": 250,
            "top_p": 0.999,
            "temperature": 1,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",
                                "data": base64_encoded_image
                            }
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ]
        }
    }

    # Convert the payload to bytes
    body_bytes = json.dumps(payload['body']).encode('utf-8')

    # Invoke the model
    response = bedrock_runtime.invoke_model(
        body=body_bytes,
        contentType=payload['contentType'],
        accept=payload['accept'],
        modelId=payload['modelId']
    )

    # Process the response
    response_body = json.loads(response['body'].read())
    result = response_body['content'][0]['text']
    return result

# def resize_image(image, max_size=1048576, quality=90):
def resize_image(image, target_size_mb=1, quality=85):
    """
    ì´ë¯¸ì§€ë¥¼ ì£¼ì–´ì§„ íƒ€ê²Ÿ ì‚¬ì´ì¦ˆ(ë©”ê°€ë°”ì´íŠ¸) ë¯¸ë§Œìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•©ë‹ˆë‹¤.
    JPEG í¬ë§·ìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì…ë‹ˆë‹¤.
    """
    # íƒ€ê²Ÿ ì‚¬ì´ì¦ˆë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜ (1MB = 1 * 1024 * 1024 ë°”ì´íŠ¸)
    target_size_bytes = target_size_mb * 1024 * 1024
    
    img_buffer = io.BytesIO()
    image.save(img_buffer, format='JPEG', quality=quality)
    img_size = img_buffer.tell()

    # ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆê°€ íƒ€ê²Ÿë³´ë‹¤ í° ê²½ìš° ë¦¬ì‚¬ì´ì¦ˆ
    while img_size > target_size_bytes:
        img_buffer = io.BytesIO()
        width, height = image.size
        # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 10%ì”© ì¤„ì„
        image = image.resize((int(width * 0.9), int(height * 0.9)), Image.Resampling.LANCZOS)
        # ë‹¤ì‹œ ì €ì¥í•˜ì—¬ ì‚¬ì´ì¦ˆ ì²´í¬
        image.save(img_buffer, format='JPEG', quality=quality)
        img_size = img_buffer.tell()

    # ë²„í¼ì˜ í¬ì§€ì…˜ì„ 0ìœ¼ë¡œ ë¦¬ì…‹
    img_buffer.seek(0)
    # BytesIO ê°ì²´ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë‹¤ì‹œ ë³€í™˜
    return Image.open(img_buffer)

def get_image_base64(image, quality=85):
    """
    ì´ë¯¸ì§€ íŒŒì¼ì„ ë°›ì•„ì„œ JPEG í¬ë§·ìœ¼ë¡œ ì••ì¶•í•˜ê³ ,
    Base64 ì¸ì½”ë”©ëœ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    `quality` íŒŒë¼ë¯¸í„°ë¡œ ì´ë¯¸ì§€ì˜ ì••ì¶• í’ˆì§ˆì„ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    buffered = io.BytesIO()
    # JPEG í¬ë§·ìœ¼ë¡œ ì´ë¯¸ì§€ ì €ì¥ ë° í’ˆì§ˆ ì¡°ì ˆ
    image.save(buffered, format="JPEG", quality=quality)
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return img_str


def main():

    opensearch_client = get_opensearch_cluster_client()
    st.set_page_config(page_title='ğŸ¤– Chat with Bedrock', layout='wide')
    st.header(':blue[Review] _ê¶ê¸ˆí•´_ :sunglasses:', divider='rainbow')    


    with st.sidebar:
        st.sidebar.markdown(
            ':smile: **Createby:** chiholee@amazon.com', unsafe_allow_html=True)
        st.sidebar.markdown('---')
        st.title("IMG Upload")        
        img_file = st.file_uploader(
            "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=['jpg', 'png', 'jpeg'])
        
        if img_file is not None :
            st.session_state['img_file'] = img_file
        
        st.sidebar.markdown('---')
        st.title("RAG Embedding")        
        pdf_file = st.file_uploader(
            "PDF ì—…ë¡œë“œë¥¼ í†µí•´ ì¶”ê°€ í•™ìŠµì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", type=["pdf"], key=None)

        if 'last_uploaded' not in st.session_state:
            st.session_state.last_uploaded = None

        if pdf_file is not None and pdf_file != st.session_state.last_uploaded:
            progress_text = st.empty()
            st.session_state['progress_bar'] = st.progress(0)
            progress_text.text("RAG(OpenSearch) ì„ë² ë”© ì¤‘...")
            record_cnt = extract_sentences_from_pdf(
                opensearch_client, pdf_file, st.session_state['progress_bar'], progress_text)
            if record_cnt > 0:
                st.session_state['processed'] = True
                st.session_state['record_cnt'] = record_cnt
                st.session_state['progress_bar'].progress(100)
                st.session_state.last_uploaded = pdf_file
                st.success(f"{record_cnt} Vector ì„ë² ë”© ì™„ë£Œ!")

    if 'img_file' in st.session_state :
        col1, col2 = st.columns(2)

        image = Image.open(st.session_state['img_file'])        
        # image = resize_image(image)

        with col1:
            st.header("ì´ë¯¸ì§€")
            st.image(image, caption='Uploaded Image.', use_column_width=True)

        # í…ìŠ¤íŠ¸ ì…ë ¥ ë°•ìŠ¤ë¥¼ ì˜¤ë¥¸ìª½ ì»¬ëŸ¼ì— ë°°ì¹˜
        with col2:
            review = scan_using_bedrock(image)
            print(review)
            st.header("ë¦¬ë·°")
            # ì‚¬ìš©ì ì…ë ¥ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì—ì–´ë¦¬ì–´
            # image_description = st.text_area("ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”.", height=300)
            st.markdown(review, unsafe_allow_html=True)



if __name__ == "__main__":
    main()
